{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaCy-intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPoh51dewEUit8gh0c31X1a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeerChristensen/NLP-Demos/blob/main/SpaCy_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9w-bTdD6HW2"
      },
      "source": [
        "# A quick introduction to SpaCy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10espGztGC4u"
      },
      "source": [
        "### Getting started\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m72kwWNhHOSI"
      },
      "source": [
        "Upgrading SpaCy is necessary for use with Colab. \n",
        "Here, we download a small Danish model. \n",
        "\n",
        "Other options include `da_core_news_lg` and a transfomer model - `da_core_news_trf` (i.e. Maltehb/danish-bert-botxo - also available through Huggingface)\n",
        "\n",
        "More information about Danish models [here](https://spacy.io/models/da)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnjb4m5V5w4q",
        "outputId": "14cb1eb2-e6f4-493d-ebc1-af61272a33f9"
      },
      "source": [
        "!pip install --upgrade spacy\n",
        "!python -m spacy download da_core_news_sm\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"da_core_news_sm\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 18.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 62.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 25.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 72.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n",
            "Collecting da-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/da_core_news_sm-3.2.0/da_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from da-core-news-sm==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->da-core-news-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: da-core-news-sm\n",
            "Successfully installed da-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('da_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdvQX7rn9rad"
      },
      "source": [
        "text = \"Mens pandemien er i vækst over store dele af Europa, er en ny og bekymrende coronavariant ved navn Omikron opdaget i Sydafrika.\"\n",
        "\n",
        "doc = nlp(text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYvZmItNar2"
      },
      "source": [
        "### What's in the `doc` container?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u91rILCteQGy"
      },
      "source": [
        "The `doc` variable contains a a sequence of tokens with a bunch of information attached.\n",
        "\n",
        "Here, we create and use a function to return a dataframe with some key info."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt7MpKIrKAsG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def df_from_text(text):\n",
        "\n",
        "  cols = (\"token\", \"lemma\", \"POS\", \"POSexplained\", \"stopword\")\n",
        "  rows = []\n",
        "\n",
        "  for word in doc:\n",
        "    row = [word.text, word.lemma_, word.pos_, spacy.explain(word.pos_), word.is_stop]\n",
        "    rows.append(row)\n",
        "\n",
        "  return pd.DataFrame(rows, columns=cols)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "YRDnL2b6jTcJ",
        "outputId": "84a05f13-6e09-47e8-9d18-691a2788e830"
      },
      "source": [
        "df_from_text(text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>POS</th>\n",
              "      <th>POSexplained</th>\n",
              "      <th>stopword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mens</td>\n",
              "      <td>Mens</td>\n",
              "      <td>SCONJ</td>\n",
              "      <td>subordinating conjunction</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pandemien</td>\n",
              "      <td>pandemien</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>er</td>\n",
              "      <td>være</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i</td>\n",
              "      <td>i</td>\n",
              "      <td>ADP</td>\n",
              "      <td>adposition</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vækst</td>\n",
              "      <td>vækst</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>over</td>\n",
              "      <td>over</td>\n",
              "      <td>ADP</td>\n",
              "      <td>adposition</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>store</td>\n",
              "      <td>stor</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>dele</td>\n",
              "      <td>del</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>af</td>\n",
              "      <td>af</td>\n",
              "      <td>ADP</td>\n",
              "      <td>adposition</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Europa</td>\n",
              "      <td>Europa</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>proper noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>er</td>\n",
              "      <td>være</td>\n",
              "      <td>AUX</td>\n",
              "      <td>auxiliary</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ny</td>\n",
              "      <td>ny</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>og</td>\n",
              "      <td>og</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>coordinating conjunction</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bekymrende</td>\n",
              "      <td>bekymre</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>coronavariant</td>\n",
              "      <td>coronavariant</td>\n",
              "      <td>ADV</td>\n",
              "      <td>adverb</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ved</td>\n",
              "      <td>vide</td>\n",
              "      <td>ADP</td>\n",
              "      <td>adposition</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>navn</td>\n",
              "      <td>navn</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Omikron</td>\n",
              "      <td>Omikron</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>proper noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>opdaget</td>\n",
              "      <td>opdage</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i</td>\n",
              "      <td>i</td>\n",
              "      <td>ADP</td>\n",
              "      <td>adposition</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Sydafrika</td>\n",
              "      <td>Sydafrika</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>proper noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            token          lemma    POS               POSexplained  stopword\n",
              "0            Mens           Mens  SCONJ  subordinating conjunction      True\n",
              "1       pandemien      pandemien   NOUN                       noun     False\n",
              "2              er           være   VERB                       verb      True\n",
              "3               i              i    ADP                 adposition      True\n",
              "4           vækst          vækst   NOUN                       noun     False\n",
              "5            over           over    ADP                 adposition      True\n",
              "6           store           stor    ADJ                  adjective     False\n",
              "7            dele            del   NOUN                       noun     False\n",
              "8              af             af    ADP                 adposition      True\n",
              "9          Europa         Europa  PROPN                proper noun     False\n",
              "10              ,              ,  PUNCT                punctuation     False\n",
              "11             er           være    AUX                  auxiliary      True\n",
              "12             en             en    DET                 determiner      True\n",
              "13             ny             ny    ADJ                  adjective      True\n",
              "14             og             og  CCONJ   coordinating conjunction      True\n",
              "15     bekymrende        bekymre   VERB                       verb     False\n",
              "16  coronavariant  coronavariant    ADV                     adverb     False\n",
              "17            ved           vide    ADP                 adposition      True\n",
              "18           navn           navn   NOUN                       noun     False\n",
              "19        Omikron        Omikron  PROPN                proper noun     False\n",
              "20        opdaget         opdage   VERB                       verb     False\n",
              "21              i              i    ADP                 adposition      True\n",
              "22      Sydafrika      Sydafrika  PROPN                proper noun     False\n",
              "23              .              .  PUNCT                punctuation     False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBSwhWIze2N2"
      },
      "source": [
        "### Extracting named entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PloVL_TKfAOG"
      },
      "source": [
        "Most models can extract named **persons**, **locations** and **organizations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Doh0-uLNHdu"
      },
      "source": [
        "text2 = \"Du forbinder nok jul med pebernødder, risalamande og brunkager, men hvordan smager julen i Bulgarien, Italien og Sverige?\"\n",
        "\n",
        "def get_entities(text):\n",
        "\n",
        "  cols = (\"entity\", \"label\", \"start\", \"end\")\n",
        "  rows = []\n",
        "\n",
        "  doc = nlp(text)\n",
        "  for ent in doc.ents:\n",
        "    row = [ent.text, ent.label_, ent.start_char, ent.end_char]\n",
        "    rows.append(row)\n",
        "\n",
        "  return pd.DataFrame(rows, columns=cols)\n",
        "    \n",
        "get_entities(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwF_4NvuogIw"
      },
      "source": [
        "With the Displacy library, visualizing named entities within text is easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T154Te5xo8Ra"
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "text3 = \"Det kommer næppe som en stor overraskelse, at Donald Trump endnu engang ikke har noget pænt at sige om hertuginde Meghan, der er gift med Storbritanniens prins Harry.  Den forhenværende amerikanske præsident har tidligere udtalt, at han »ikke er fan af Meghan«, og nu forklarer Donald Trump sig i et interview til den tidligere UKIP-formand, Nigel Farage.  I interviewet, der sendes i aften på britisk tv, beskylder Donald Trump hertuginde Meghan for at »mangle respekt« og for at »skade« dronning Elizabeth, skriver The Daily Mail. Donald Trump kommenterer også beskyldninger om, at hertuginden skulle være manipulerende over for sin mand. Hun skulle ifølge anklagerne være den direkte årsag til,  at hertugparret i begyndelsen af 2020 valgte at træde ud af den kongelige familie for i stedet at flytte USA.\"\n",
        "\n",
        "doc = nlp(text3)\n",
        "\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB3hTFrHg7RK"
      },
      "source": [
        "### Tokenization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjtsFPHXj7Mj"
      },
      "source": [
        "For downstream tasks such as text classification or topic modelling, we might try different ways of preprocessing texts.\n",
        "\n",
        "In this case, we create a function that only outputs lemmatized nouns transformed to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzkbzeC9hEX2"
      },
      "source": [
        "def noun_lemmatizer(sentence):\n",
        "    \"\"\"Using SpaCy to lemmatize and extract nouns\"\"\"\n",
        "    tokens = nlp(sentence)\n",
        "    tokens = [word.lemma_.lower() for word in tokens if word.pos_ == \"NOUN\"]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOrvEdZ4iwdT"
      },
      "source": [
        "text4 = \"Du forbinder nok jul med pebernødder, risalamande og brunkager, men hvordan smager julen i Bulgarien, Italien og Sverige?\"\n",
        "\n",
        "noun_lemmatizer(text4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_UPDgYFl8b_"
      },
      "source": [
        "### Getting noun phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVcaATn4lgwm"
      },
      "source": [
        "text5 = \"Jeg er den stolte ejer af to store røde biler.\"\n",
        "\n",
        "doc = nlp(text5)\n",
        "\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(f\"> {chunk.text}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4TQEbr8xL8H"
      },
      "source": [
        "### Leaner pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJjb_a7o0EkK"
      },
      "source": [
        "The default processing pipeline includes a tagger, a lemmatizer, a parser and an entity recognizer. Each pipeline component returns the processed Doc, which is then passed on to the next component.\n",
        "\n",
        "We may choose to only keep some of the processing components in the pipeline.\n",
        "This can help you process text faster.\n",
        "\n",
        "In this case, we disable several unnecessary steps for NER.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp1PWLA4xuab"
      },
      "source": [
        "texts = [text, text2, text3, text4, text5]\n",
        "\n",
        "for doc in nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
        "\n",
        "    print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}