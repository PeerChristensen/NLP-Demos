{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "da_transfomers-intro.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "j31PJpJfhAdD",
        "0eYgL8eev7SI",
        "EFRinHp2t3jX"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYpk+S4LITJEknsrgThjpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a600b57e9dbb43188fde95abb8f8c187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bbfa1fc218ed4e44bbd2b91d7dd44093",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bf8d1b1dd1749d78404b457131a4192",
              "IPY_MODEL_1246838a72d34cb8a5ad11ed1b9e9439",
              "IPY_MODEL_06bafd37c1e74eb680d0cb594352c5a1"
            ]
          }
        },
        "bbfa1fc218ed4e44bbd2b91d7dd44093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bf8d1b1dd1749d78404b457131a4192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc79a55cd59041768b8f2011612909da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39ec1ffa68714179ac80115cc29d65dc"
          }
        },
        "1246838a72d34cb8a5ad11ed1b9e9439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10336de74b804bcca757e387bb6cd6c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442559917,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442559917,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2317be1230c144a6aabad4810df5d7b0"
          }
        },
        "06bafd37c1e74eb680d0cb594352c5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16c79400d4e541029f161418b48b3b0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 422M/422M [00:11&lt;00:00, 40.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_590ef9e6443b45ae9735a784207fd16d"
          }
        },
        "fc79a55cd59041768b8f2011612909da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39ec1ffa68714179ac80115cc29d65dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10336de74b804bcca757e387bb6cd6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2317be1230c144a6aabad4810df5d7b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16c79400d4e541029f161418b48b3b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "590ef9e6443b45ae9735a784207fd16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeerChristensen/NLP-Demos/blob/main/da_transfomers_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUHwuaqIaSTA"
      },
      "source": [
        "# Some examples using (Danish) transfomer models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18B0xgqOVXDq"
      },
      "source": [
        "## Named entity recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhFw8WQJah3N"
      },
      "source": [
        "We get the current best model for Danish NER. It can be found [here](\"https://huggingface.co/saattrupdan/nbailab-base-ner-scandi\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH9ZkjLgRplI",
        "outputId": "d9e39456-3aad-47a1-8cea-4ffaf8fd08f5"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "model = 'saattrupdan/nbailab-base-ner-scandi'\n",
        "ner = pipeline(\"ner\", model=model, aggregation_strategy='first', )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF1NNdImUGmv"
      },
      "source": [
        "text = \"Margrethe Laursen, bosiddende på adressen Vibevej 25 i København, blev indlagt på Bispebjerg Hospital efter en ulykke i forbindelse med hendes arbejde ved Movia. Hun blev behandlet af Overlæge Jens Severinsen.\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UrXQ_pPT-Fm",
        "outputId": "df535ed2-7374-45b5-aba5-fc0032522cc2"
      },
      "source": [
        "ner(text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 17,\n",
              "  'entity_group': 'PER',\n",
              "  'score': 0.99971926,\n",
              "  'start': 0,\n",
              "  'word': 'Margrethe Laursen'},\n",
              " {'end': 52,\n",
              "  'entity_group': 'LOC',\n",
              "  'score': 0.9973518,\n",
              "  'start': 42,\n",
              "  'word': 'Vibevej 25'},\n",
              " {'end': 64,\n",
              "  'entity_group': 'LOC',\n",
              "  'score': 0.99921095,\n",
              "  'start': 55,\n",
              "  'word': 'København'},\n",
              " {'end': 101,\n",
              "  'entity_group': 'LOC',\n",
              "  'score': 0.9718465,\n",
              "  'start': 82,\n",
              "  'word': 'Bispebjerg Hospital'},\n",
              " {'end': 160,\n",
              "  'entity_group': 'ORG',\n",
              "  'score': 0.9937564,\n",
              "  'start': 155,\n",
              "  'word': 'Movia'},\n",
              " {'end': 208,\n",
              "  'entity_group': 'PER',\n",
              "  'score': 0.94952404,\n",
              "  'start': 193,\n",
              "  'word': 'Jens Severinsen'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW3Y5XkpbBRx"
      },
      "source": [
        "Given the standard output, we can make a function that anonymizes text by removing named entities based on character positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIn6ZBFS_l4"
      },
      "source": [
        "def find_and_remove_named_entities(text: str) -> str:\n",
        "    \"\"\"Use current best NER model (saattrupdan/nbailab-base-ner-scandi) to identify named entities.\n",
        "    Entities are removed by position ranges within strings.\n",
        "    The model and pipeline are defined outside this function.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        named_ents = ner(text)\n",
        "        ranges_to_remove = [range(i[\"start\"], i[\"end\"]) for i in named_ents]\n",
        "        new_text = ''.join([char for idx, char in enumerate(text) if not any(idx in rng for rng in ranges_to_remove)])\n",
        "        return new_text\n",
        "    except:\n",
        "        return text"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xh062PG2TALG",
        "outputId": "8227ff48-ec27-40b9-b19c-8527800edb3b"
      },
      "source": [
        "find_and_remove_named_entities(text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "', bosiddende på adressen  i , blev indlagt på  efter en ulykke i forbindelse med hendes arbejde ved . Hun blev behandlet af Overlæge .'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vyrA7ojeavk"
      },
      "source": [
        "## Translation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUQF3INJmHKK"
      },
      "source": [
        "### A quick example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX-te4mimGYi",
        "outputId": "ef8bfc6a-4f7a-4c04-dedc-903bd4f84392"
      },
      "source": [
        "!pip install sentencepiece\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-da\",truncation=True, max_length=500)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-da\")\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Jeg ønsker at leve, jeg vil give. Jeg har været en minearbejder for et hjerte af guld\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gtji6KCmoyO",
        "outputId": "bd3fc9f7-fb1d-4925-8ed3-e14f64f495cd"
      },
      "source": [
        "translation = pipeline(\"translation_en_to_da\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "text = \"I want to live, I want to give. I've been a miner for a heart of gold\"\n",
        "\n",
        "translated_text = translation(text)[0]['translation_text']\n",
        "print(translated_text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jeg ønsker at leve, jeg vil give. Jeg har været en minearbejder for et hjerte af guld\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc7OmqamnrXD"
      },
      "source": [
        "### A not so quick *example*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0dTZ03woMPx"
      },
      "source": [
        "In this example, we'll see how to translate The Da Vinci Code in .epub format into Danish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYJ2AdgFehDc",
        "outputId": "8aff6d09-d94a-42ba-e85e-5d88928b2674"
      },
      "source": [
        "!pip install epub-conversion\n",
        "!pip install xml_cleaner\n",
        "\n",
        "from epub_conversion.utils import open_book, convert_epub_to_lines\n",
        "import re, time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: epub-conversion in /usr/local/lib/python3.7/dist-packages (1.0.15)\n",
            "Requirement already satisfied: epub in /usr/local/lib/python3.7/dist-packages (from epub-conversion) (0.5.2)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.7/dist-packages (from epub-conversion) (0.98)\n",
            "Requirement already satisfied: ciseau in /usr/local/lib/python3.7/dist-packages (from epub-conversion) (1.0.1)\n",
            "Requirement already satisfied: xml_cleaner in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j31PJpJfhAdD"
      },
      "source": [
        "#### Preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdbeZtcxiNJ5"
      },
      "source": [
        "def clean_text(text):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', text)\n",
        "  return cleantext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZcfxLlShLIJ"
      },
      "source": [
        "book = open_book(\"/Users/peerchristensen/Downloads/DaVinciCode.epub\")\n",
        "\n",
        "lines = convert_epub_to_lines(book)\n",
        "\n",
        "cleaned_text = [clean_text(line) for line in lines]\n",
        "\n",
        "cleaned_text = [text.strip() for text in cleaned_text]\n",
        "\n",
        "cleaned_text = list(filter(None, cleaned_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-X8x9yXp1ZV"
      },
      "source": [
        "We can use a dataframe to store the original and translated text to better evaluate the quality of the translations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOpBNDR-iznN"
      },
      "source": [
        "df = pd.DataFrame({'text': cleaned_text})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xZTp8riqo6l"
      },
      "source": [
        "#### Translate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po50rh_Aq82S"
      },
      "source": [
        "def translate(text):\n",
        "    if text is None or text == \"\":\n",
        "        return \"Error\",\n",
        "\n",
        "    #batch input + sentence tokenization\n",
        "    batch = tokenizer.prepare_seq2seq_batch(sent_tokenize(text))\n",
        "\n",
        "    #run model\n",
        "    translated = model.generate(**batch)\n",
        "    tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "\n",
        "    return \" \".join(tgt_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYpZ_RIxrWpx"
      },
      "source": [
        "df['translated'] = df[\"clean_text\"].map(lambda x: translate(x)).copy()\n",
        "\n",
        "df.to_csv('translated_auto.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eMJbtlbt13-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmPM9JxTYyDD"
      },
      "source": [
        "## Fine-tuning for domain adaptation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MR9jujFZrt9"
      },
      "source": [
        "text = \"Software developers and data scientist use computers to write emails and code.\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7H0D9LHaGx2"
      },
      "source": [
        "### General"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0JHw2yhiaQ30",
        "outputId": "26b3049f-5ead-45c6-c8f8-b6b304f7d2de"
      },
      "source": [
        "model = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "translator = pipeline(\"translation\", model=model)\n",
        "\n",
        "translation = translator(text)\n",
        "translation[0]['translation_text']"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Les développeurs de logiciels et les data scientist utilisent des ordinateurs pour écrire des courriels et des codes.'"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvspHFupaOCc"
      },
      "source": [
        "### Domain-specific"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XQ0ArUn_Y4Le",
        "outputId": "4561188d-6b5b-45cc-fd2f-616d5b3e09fc"
      },
      "source": [
        "model = \"huggingface-course/marian-finetuned-kde4-en-to-fr\"\n",
        "translator = pipeline(\"translation\", model=model)\n",
        "\n",
        "translation = translator(text)\n",
        "translation[0]['translation_text']"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Les développeurs de logiciels et les informaticiens utilisent les ordinateurs pour écrire des courriers électroniques et du code.'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eYgL8eev7SI"
      },
      "source": [
        "## Sequence classification/Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a600b57e9dbb43188fde95abb8f8c187",
            "bbfa1fc218ed4e44bbd2b91d7dd44093",
            "9bf8d1b1dd1749d78404b457131a4192",
            "1246838a72d34cb8a5ad11ed1b9e9439",
            "06bafd37c1e74eb680d0cb594352c5a1",
            "fc79a55cd59041768b8f2011612909da",
            "39ec1ffa68714179ac80115cc29d65dc",
            "10336de74b804bcca757e387bb6cd6c3",
            "2317be1230c144a6aabad4810df5d7b0",
            "16c79400d4e541029f161418b48b3b0d",
            "590ef9e6443b45ae9735a784207fd16d"
          ]
        },
        "id": "w43c67_mwA8q",
        "outputId": "98a3999c-679c-4e41-8879-eaebc49801ef"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"DaNLP/da-bert-tone-sentiment-polarity\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"DaNLP/da-bert-tone-sentiment-polarity\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a600b57e9dbb43188fde95abb8f8c187",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsD8ZbOrx0Qz"
      },
      "source": [
        "texts = [\"Dette er intet mindre end et fantastisk produkt!\", \"Jeg er ret skuffet over den dårlige service.\"]\n",
        "\n",
        "clf = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKe53JKsz2rn",
        "outputId": "ac234953-b5d4-4384-f2d5-b980be0070fb"
      },
      "source": [
        "clf(texts)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9985690116882324},\n",
              " {'label': 'negative', 'score': 0.996193528175354}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "JCxTPU3cyZrq",
        "outputId": "e07ba195-ad13-463e-ff62-e734567d9d57"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(clf(texts))\n",
        "df[\"text\"] = texts\n",
        "df = df[ ['text'] + [ col for col in df.columns if col != 'text' ] ]\n",
        "df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dette er intet mindre end et fantastisk produkt!</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jeg er ret skuffet over den dårlige service.</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.996194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               text     label     score\n",
              "0  Dette er intet mindre end et fantastisk produkt!  positive  0.998569\n",
              "1      Jeg er ret skuffet over den dårlige service.  negative  0.996194"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFRinHp2t3jX"
      },
      "source": [
        "## Zero-shot classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFdH_fuISUMd"
      },
      "source": [
        "\"*The zero-shot pipeline in the Transformers library treats text classification as natural language inference (NLI). This approach was pioneered by Yin et al. in 2019. In NLI, a model takes two sentences as input — a premise and a hypothesis — and decides whether the hypothesis follows from the premise (entailment), contradicts it (contradiction), or neither (neutral). For example, the premise David killed Goliath entails the hypothesis Goliath is dead, is contradicted by Goliath is alive and doesn’t allow us to draw any conclusions about Goliath is a giant. This NLI template can be reused for text classification by taking the text we’d like to label as the premise, and rephrasing every candidate class as a hypothesis.*\" \n",
        "\n",
        "https://nlp.town/blog/zero-shot-classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJgg9ABl1-Aq"
      },
      "source": [
        "If more than one label can be true, we may set `multi_class=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAWdErGdt-k5"
      },
      "source": [
        "clf = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcYYgBwR2R1Y",
        "outputId": "c6e8026e-1c52-4596-e3dd-7671975da4ee"
      },
      "source": [
        "texts = [\"The expansion of the playoff field to include the top 14 teams ranks among the best decisions the league has made in recent years. An additional postseason bid for each conference has translated into an increased level of competition while also creating greater intrigue around those middle-of-the-pack teams.\"]\n",
        "candidate_labels = ['travel', 'sports', 'cooking', 'politics']\n",
        "clf(texts, candidate_labels)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'labels': ['sports', 'cooking', 'travel', 'politics'],\n",
              "  'scores': [0.7761102914810181,\n",
              "   0.11519002914428711,\n",
              "   0.07371588051319122,\n",
              "   0.03498377650976181],\n",
              "  'sequence': 'The expansion of the playoff field to include the top 14 teams ranks among the best decisions the league has made in recent years. An additional postseason bid for each conference has translated into an increased level of competition while also creating greater intrigue around those middle-of-the-pack teams.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}